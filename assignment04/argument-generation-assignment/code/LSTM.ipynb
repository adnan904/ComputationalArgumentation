{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from attention import AttentionLayer\n",
    "from contraction import contraction_mapping\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_WORKING_DIR = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(\"__file__\")))\n",
    "CORPUS_PATH = f'{CURRENT_WORKING_DIR}/../data/essay_prompt_corpus.json'\n",
    "SPLIT_FILE_PATH = f'{CURRENT_WORKING_DIR}/../data/train-test-split.csv'\n",
    "PRED_FILE_PATH= f'{CURRENT_WORKING_DIR}/../data/predictions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split_essays(corpus, split_scheme) -> (list, list):\n",
    "    \"\"\"\n",
    "    :param corpus: unified data file with all the essays\n",
    "    :param split_scheme: train_test_split scheme file\n",
    "    :rtype: list, list\n",
    "    :return: pandas dataframe of train, test split essay id, text, prompt\n",
    "    \"\"\"\n",
    "\n",
    "    train_test_split_dict = {}\n",
    "    test_df = pd.DataFrame(columns=['id', 'text', 'prompt'])\n",
    "    train_df = pd.DataFrame(columns=['id', 'text', 'prompt'])\n",
    "\n",
    "    # create a dict of the type: {essay_id: Tag},  where Tag = 'TRAIN' or 'TEST'\n",
    "    for row in split_scheme:\n",
    "        if len(row) > 0:\n",
    "            essay_id = int(row[0].split('essay')[1])\n",
    "            train_test_split_dict[essay_id] = row[1]\n",
    "\n",
    "    # extract essays that match the test_train_split scheme\n",
    "    for essay in corpus:\n",
    "        if train_test_split_dict[int(essay['id'])] == 'TRAIN':\n",
    "            train_df = train_df.append({'id': essay['id'], 'text': essay['text'], 'prompt': essay['prompt']},\n",
    "                                       ignore_index=True)\n",
    "        else:\n",
    "            test_df = test_df.append({'id': essay['id'], 'text': essay['text'], 'prompt': essay['prompt']},\n",
    "                                     ignore_index=True)\n",
    "    train_df.sort_values('id', inplace=True)\n",
    "    test_df.sort_values('id', inplace=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_corpus = json.load(open(CORPUS_PATH, encoding='utf-8'))\n",
    "\n",
    "# Read train_test_split and get essays from the unified corpus based on the split\n",
    "with open(SPLIT_FILE_PATH, newline='', encoding='utf-8') as csvfile:\n",
    "    train_test_split_file = csv.reader(csvfile, delimiter=';')\n",
    "    next(train_test_split_file, None)\n",
    "    train_essays, test_essays = get_train_test_split_essays(json_corpus, train_test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text, num):\n",
    "    \"\"\"\n",
    "        Performs the following on input text:\n",
    "            1.Convert everything to lowercase\n",
    "            2.Contraction mapping\n",
    "            3.Remove (â€˜s)\n",
    "            4.Remove any text inside the parenthesis ( )\n",
    "            5.Eliminate punctuations and special characters\n",
    "            6.Remove stopwords\n",
    "            7.Remove short words\n",
    "    \"\"\"\n",
    "    new_string = text.lower()\n",
    "    new_string = re.sub(r'\\([^)]*\\)', '', new_string)\n",
    "    new_string = re.sub('\"', '', new_string)\n",
    "    new_string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(\" \")])\n",
    "    new_string = re.sub(r\"'s\\b\", \"\", new_string)\n",
    "    new_string = re.sub(\"[^a-zA-Z]\", \" \", new_string)\n",
    "    new_string = re.sub('[m]{2,}', 'mm', new_string)\n",
    "    if num == 0:\n",
    "        tokens = [w for w in new_string.split() if w not in stop_words]\n",
    "    else:\n",
    "        tokens = new_string.split()\n",
    "    long_words = []\n",
    "    for i in tokens:\n",
    "        if len(i) > 1:                                                 # removing short word\n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in train_essays['text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['always said competition effectively promote development economy order survive competition companies continue improve products service result whole society prospers however discuss issue competition cooperation concerned whole society development individual whole life point view firmly believe attach importance cooperation primary education first cooperation children learn interpersonal skills significant future life students acquired team work achieve goal others importantly get along others process cooperation children learn listen opinions others communicate others think comprehensively even compromise team members conflicts occurred skills help get well people benefit whole life hand significance competition become excellence gain victory hence always said competition makes society effective however consider question win game always find need cooperation greater goal competition need take olympic games form competition instance hard imagine athlete could win game without training coach help professional staffs people take care diet charge medical care winner athlete success belongs whole team therefore without cooperation would victory competition consequently matter view individual development relationship competition cooperation receive conclusion cooperative attitudes towards life profitable one success']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in train_essays['prompt']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['should students be taught to compete or to cooperate']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essays['cleaned_text']=cleaned_text\n",
    "train_essays['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essays.replace('', np.nan, inplace=True)\n",
    "train_essays.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in train_essays['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in train_essays['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937888198757764\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in train_essays['cleaned_summary']:\n",
    "    if(len(i.split())<= 17):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(train_essays['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in train_essays['cleaned_text']:\n",
    "    if(len(i.split())<= 252):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(train_essays['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=252\n",
    "max_summary_len=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':train_essays['cleaned_text'],'summary':train_essays['cleaned_summary']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer() \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 289)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 252)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 252, 100)     216400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 252, 300), ( 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 252, 300), ( 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    7200        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 252, 300), ( 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 72)     43272       concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,851,972\n",
      "Trainable params: 2,851,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 3.9609 - val_loss: 3.4101\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 2.4832 - val_loss: 1.3123\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.4511 - val_loss: 1.3743\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.4397 - val_loss: 1.2786\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.3834 - val_loss: 1.2541\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3766 - val_loss: 1.2359\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3612 - val_loss: 1.2252\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3550 - val_loss: 1.3106\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3838 - val_loss: 1.2241\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3523 - val_loss: 1.2458\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3267 - val_loss: 1.1783\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.2910 - val_loss: 1.1633\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.2762 - val_loss: 1.2435\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.3248 - val_loss: 1.1524\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.2438 - val_loss: 1.1214\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.2107 - val_loss: 1.1336\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.2111 - val_loss: 1.1599\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=18,\n",
    "                  callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], \n",
    "                                                                  y_val.reshape(y_val.shape[0],\n",
    "                                                                                y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: good or \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: government should be for education and or not \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: some young their parents \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: and good of and your \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: have \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: do you it is good for to work \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: parents or should important for their \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: technology to people more \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: are in of \n",
      "Predicted summary:  should\n",
      "\n",
      "\n",
      "Original summary: should be \n",
      "Predicted summary:  should\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\"Original summary:\",seq2summary(y_val[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
