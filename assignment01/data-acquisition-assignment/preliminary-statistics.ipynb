{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import os\n",
    "# Loading the Spacy Language Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# PLEASE SET TO CORRECT PATH BEFORE RUNNING #\n",
    "#############################################\n",
    "CURRENT_WORKING_DIR = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(\"__file__\")))\n",
    "UNIFIED_DATA_FILE_PATH = f'{CURRENT_WORKING_DIR}/code/data/unified_data.json'\n",
    "TRAIN_TEST_SPLIT_FILE_PATH = f'{CURRENT_WORKING_DIR}/code/data/train-test-split.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_split() -> list:\n",
    "    \"\"\"\n",
    "    Reads the train-test-split.csv file and returns a list of ids of all the essays that have been SET for 'TRAIN'\n",
    "    :return: train_ids : integer IDs of the essays SET as 'TRAIN'\n",
    "    \"\"\"\n",
    "    with open(TRAIN_TEST_SPLIT_FILE_PATH, 'r') as train_file:\n",
    "        train_ids = []\n",
    "        file_content = train_file.read().split('\\n')[1:]\n",
    "        for line in file_content:\n",
    "            if 'TRAIN' in line:\n",
    "                train_ids.append(line.split('\";')[0].split('\"essay')[1])\n",
    "        return train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all the Statistic Variables\n",
    "num_of_essays = 0\n",
    "num_of_paragraphs = 0\n",
    "num_of_sentences = 0\n",
    "num_of_tokens = 0\n",
    "num_of_major_claims = 0\n",
    "num_of_claims = 0\n",
    "num_of_premises = 0\n",
    "num_of_essays_with_conf_bias = 0\n",
    "num_of_essays_without_conf_bias = 0\n",
    "num_of_suff_paras = 0\n",
    "num_of_insuff_paras = 0\n",
    "num_of_tokens_in_major_claims = 0\n",
    "num_of_tokens_in_claims = 0\n",
    "num_of_tokens_in_premises = 0\n",
    "avg_num_of_tokens_in_major_claims = 0\n",
    "avg_num_of_tokens_in_claims = 0\n",
    "avg_num_of_tokens_in_premises = 0\n",
    "ten_most_spec_words_in_major_claims = 0\n",
    "ten_most_spec_words_in_claims = 0\n",
    "ten_most_spec_words_in_premises = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of IDs of train-split from train-test-split.csv\n",
    "train_split_essay_ids = get_train_split()\n",
    "# Number of Essays = Number of Essays in the train-test-split.csv file that have been SET 'TRAIN'\n",
    "num_of_essays = len(train_split_essay_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(UNIFIED_DATA_FILE_PATH, 'r') as f:\n",
    "    unified_file = json.load(f)\n",
    "    for essay in unified_file:\n",
    "        # We only need to compute for essays SET to 'TRAIN'\n",
    "        if essay['id'] in train_split_essay_ids:\n",
    "            # Tokenizing the text for the essay using the spaCy library\n",
    "            text = nlp(essay['text'])\n",
    "            num_of_paragraphs += len(essay['paragraphs'])\n",
    "            # Using the spaCy library for calculating Sentences in the text\n",
    "            num_of_sentences += len(list(text.sents))\n",
    "            num_of_tokens += len(text)\n",
    "            num_of_major_claims += len(essay['major_claim'])\n",
    "            num_of_claims += len(essay['claims'])\n",
    "            num_of_premises += len(essay['premises'])\n",
    "            if essay['confirmation_bias']:\n",
    "                num_of_essays_with_conf_bias += 1\n",
    "            else:\n",
    "                num_of_essays_without_conf_bias += 1\n",
    "            for para in essay['paragraphs']:\n",
    "                if para['sufficient']:\n",
    "                    num_of_suff_paras += 1\n",
    "                else:\n",
    "                    num_of_insuff_paras += 1\n",
    "            # Tokenizing using the nlp() of the spaCy library\n",
    "            for major_claim in essay['major_claim']:\n",
    "                num_of_tokens_in_major_claims += len(nlp(major_claim['text']))\n",
    "            for claim in essay['claims']:\n",
    "                num_of_tokens_in_claims += len(nlp(claim['text']))\n",
    "            for premise in essay['premises']:\n",
    "                num_of_tokens_in_premises += len(nlp(premise['text']))\n",
    "    avg_num_of_tokens_in_major_claims = num_of_tokens_in_major_claims / num_of_major_claims\n",
    "    avg_num_of_tokens_in_claims = num_of_tokens_in_claims / num_of_claims\n",
    "    avg_num_of_tokens_in_premises = num_of_tokens_in_premises / num_of_premises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Preliminary Statistics are:\n",
      "Number of essays: 322\n",
      "Number of paragraphs: 820\n",
      "Number of sentences: 5462\n",
      "Number of tokens: 116588\n",
      "Number of major claims: 598\n",
      "Number of claims: 1800\n",
      "Number of premises: 3023\n",
      "Number of essays with confirmation bias: 122\n",
      "Number of essays without confirmation bias: 200\n",
      "Number of sufficient paragraphs: 538\n",
      "Number of insufficient paragraphs: 282\n",
      "Average number of tokens in major claims: 14.695652173913043\n",
      "Average number of tokens in claims: 14.959444444444445\n",
      "Average number of tokens in premises: 17.60205094277208\n"
     ]
    }
   ],
   "source": [
    "print(\"The Preliminary Statistics are:\")\n",
    "print(\"Number of essays: \" + str(num_of_essays))\n",
    "print(\"Number of paragraphs: \" + str(num_of_paragraphs))\n",
    "print(\"Number of sentences: \" + str(num_of_sentences))\n",
    "print(\"Number of tokens: \" + str(num_of_tokens))\n",
    "print(\"Number of major claims: \" + str(num_of_major_claims))\n",
    "print(\"Number of claims: \" + str(num_of_claims))\n",
    "print(\"Number of premises: \" + str(num_of_premises))\n",
    "print(\"Number of essays with confirmation bias: \" + str(num_of_essays_with_conf_bias))\n",
    "print(\"Number of essays without confirmation bias: \" + str(num_of_essays_without_conf_bias))\n",
    "print(\"Number of sufficient paragraphs: \" + str(num_of_suff_paras))\n",
    "print(\"Number of insufficient paragraphs: \" + str(num_of_insuff_paras))\n",
    "print(\"Average number of tokens in major claims: \" + str(avg_num_of_tokens_in_major_claims))\n",
    "print(\"Average number of tokens in claims: \" + str(avg_num_of_tokens_in_claims))\n",
    "print(\"Average number of tokens in premises: \" + str(avg_num_of_tokens_in_premises))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
